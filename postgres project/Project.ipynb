{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in /Users/yuchen/anaconda3/lib/python3.6/site-packages (2.8.3)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2\n",
    "import psycopg2\n",
    "from sql_queries import create_table_queries, drop_table_queries\n",
    "\n",
    "\n",
    "def create_database():\n",
    "    # connect to default database\n",
    "    conn = psycopg2.connect(\"host=127.0.0.1 dbname=postgres user=student password=student\")\n",
    "    conn.set_session(autocommit=True)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # create sparkify database with UTF8 encoding\n",
    "    cur.execute(\"DROP DATABASE IF EXISTS sparkifydb\")\n",
    "    cur.execute(\"CREATE DATABASE sparkifydb WITH ENCODING 'utf8' TEMPLATE template0\")\n",
    "\n",
    "    # close connection to default database\n",
    "    conn.close()    \n",
    "    \n",
    "    # connect to sparkify database\n",
    "    conn = psycopg2.connect(\"host=127.0.0.1 dbname=sparkifydb user=student password=student\")\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    return cur, conn\n",
    "\n",
    "\n",
    "def drop_tables(cur, conn):\n",
    "    for query in drop_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "def create_tables(cur, conn):\n",
    "    for query in create_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "def main():\n",
    "    cur, conn = create_database()\n",
    "    \n",
    "    drop_tables(cur, conn)\n",
    "    create_tables(cur, conn)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 files found in data/song_data\n",
      "1/75 files processed.\n",
      "2/75 files processed.\n",
      "3/75 files processed.\n",
      "4/75 files processed.\n",
      "5/75 files processed.\n",
      "6/75 files processed.\n",
      "7/75 files processed.\n",
      "8/75 files processed.\n",
      "9/75 files processed.\n",
      "10/75 files processed.\n",
      "11/75 files processed.\n",
      "12/75 files processed.\n",
      "13/75 files processed.\n",
      "14/75 files processed.\n",
      "15/75 files processed.\n",
      "16/75 files processed.\n",
      "17/75 files processed.\n",
      "18/75 files processed.\n",
      "19/75 files processed.\n",
      "20/75 files processed.\n",
      "21/75 files processed.\n",
      "22/75 files processed.\n",
      "23/75 files processed.\n",
      "24/75 files processed.\n",
      "25/75 files processed.\n",
      "26/75 files processed.\n",
      "27/75 files processed.\n",
      "28/75 files processed.\n",
      "29/75 files processed.\n",
      "30/75 files processed.\n",
      "31/75 files processed.\n",
      "32/75 files processed.\n",
      "33/75 files processed.\n",
      "34/75 files processed.\n",
      "35/75 files processed.\n",
      "36/75 files processed.\n",
      "37/75 files processed.\n",
      "38/75 files processed.\n",
      "39/75 files processed.\n",
      "40/75 files processed.\n",
      "41/75 files processed.\n",
      "42/75 files processed.\n",
      "43/75 files processed.\n",
      "44/75 files processed.\n",
      "45/75 files processed.\n",
      "46/75 files processed.\n",
      "47/75 files processed.\n",
      "48/75 files processed.\n",
      "49/75 files processed.\n",
      "50/75 files processed.\n",
      "51/75 files processed.\n",
      "52/75 files processed.\n",
      "53/75 files processed.\n",
      "54/75 files processed.\n",
      "55/75 files processed.\n",
      "56/75 files processed.\n",
      "57/75 files processed.\n",
      "58/75 files processed.\n",
      "59/75 files processed.\n",
      "60/75 files processed.\n",
      "61/75 files processed.\n",
      "62/75 files processed.\n",
      "63/75 files processed.\n",
      "64/75 files processed.\n",
      "65/75 files processed.\n",
      "66/75 files processed.\n",
      "67/75 files processed.\n",
      "68/75 files processed.\n",
      "69/75 files processed.\n",
      "70/75 files processed.\n",
      "71/75 files processed.\n",
      "72/75 files processed.\n",
      "73/75 files processed.\n",
      "74/75 files processed.\n",
      "75/75 files processed.\n",
      "30 files found in data/log_data\n",
      "1/30 files processed.\n",
      "2/30 files processed.\n",
      "3/30 files processed.\n",
      "4/30 files processed.\n",
      "5/30 files processed.\n",
      "6/30 files processed.\n",
      "7/30 files processed.\n",
      "8/30 files processed.\n",
      "9/30 files processed.\n",
      "10/30 files processed.\n",
      "11/30 files processed.\n",
      "12/30 files processed.\n",
      "13/30 files processed.\n",
      "14/30 files processed.\n",
      "15/30 files processed.\n",
      "16/30 files processed.\n",
      "17/30 files processed.\n",
      "18/30 files processed.\n",
      "19/30 files processed.\n",
      "20/30 files processed.\n",
      "21/30 files processed.\n",
      "22/30 files processed.\n",
      "23/30 files processed.\n",
      "24/30 files processed.\n",
      "25/30 files processed.\n",
      "26/30 files processed.\n",
      "27/30 files processed.\n",
      "28/30 files processed.\n",
      "29/30 files processed.\n",
      "30/30 files processed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sql_queries import *\n",
    "\n",
    "\n",
    "def process_song_file(cur, filepath):\n",
    "    # open song file\n",
    "    df = pd.read_json(filepath, lines=True)\n",
    "\n",
    "    # insert song record\n",
    "    song_data = df[[\"song_id\",\"title\",\"artist_id\",\"year\",\"duration\"]].values.tolist()[0]\n",
    "    cur.execute(song_table_insert, song_data)\n",
    "    \n",
    "    # insert artist record\n",
    "    artist_data = df[[\"artist_id\",\"artist_name\",\"artist_location\",\"artist_latitude\",\"artist_longitude\"]].values.tolist()[0]\n",
    "    cur.execute(artist_table_insert, artist_data)\n",
    "\n",
    "\n",
    "def process_log_file(cur, filepath):\n",
    "    # open log file\n",
    "    df = pd.read_json(filepath, lines=True)\n",
    "\n",
    "    # filter by NextSong action\n",
    "    df = df[df['page'] == \"NextSong\"]\n",
    "\n",
    "    # convert timestamp column to datetime\n",
    "    t = df\n",
    "    \n",
    "    t['ts'] = pd.to_datetime(t['ts'], unit='ms')\n",
    "    t['hour'] = t['ts'].dt.hour\n",
    "    t['day'] = t['ts'].dt.day\n",
    "    t['week'] = t['ts'].dt.week\n",
    "    t['month'] = t['ts'].dt.month\n",
    "    t['year'] = t['ts'].dt.year\n",
    "    t['weekday'] = t['ts'].dt.weekday\n",
    "    \n",
    "    # insert time data records\n",
    "    time_data = [\"ts\", \"hour\", \"day\", \"week\", \"month\", \"year\", \"weekday\"]\n",
    "    column_labels = [\"start_time\", \"hour\", \"day\", \"week\", \"month\", \"year\", \"weekday\"]\n",
    "    time_df = t[time_data]\n",
    "    time_df.columns = column_labels\n",
    "\n",
    "    for i, row in time_df.iterrows():\n",
    "        cur.execute(time_table_insert, list(row))\n",
    "\n",
    "    # load user table\n",
    "    user_df = df[['userId','firstName','lastName',\"gender\",\"level\"]]\n",
    "\n",
    "    # insert user records\n",
    "    for i, row in user_df.iterrows():\n",
    "        cur.execute(user_table_insert, row)\n",
    "\n",
    "    # insert songplay records\n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        # get songid and artistid from song and artist tables\n",
    "        cur.execute(song_select, (row.song, row.artist, row.length))\n",
    "        results = cur.fetchone()\n",
    "        \n",
    "        if results:\n",
    "            songid, artistid = results\n",
    "        else:\n",
    "            songid, artistid = None, None\n",
    "\n",
    "        # insert songplay record\n",
    "        songplay_data = [index, row.ts, row.userId, row.level, songid, artistid, row.sessionId, row.location, row.userAgent]\n",
    "        cur.execute(songplay_table_insert, songplay_data)\n",
    "\n",
    "\n",
    "def process_data(cur, conn, filepath, func):\n",
    "    # get all files matching extension from directory\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        files = glob.glob(os.path.join(root,'*.json'))\n",
    "        for f in files :\n",
    "            all_files.append(os.path.abspath(f))\n",
    "\n",
    "    # get total number of files found\n",
    "    num_files = len(all_files)\n",
    "    print('{} files found in {}'.format(num_files, filepath))\n",
    "\n",
    "    # iterate over files and process\n",
    "    for i, datafile in enumerate(all_files, 1):\n",
    "        func(cur, datafile)\n",
    "        conn.commit()\n",
    "        print('{}/{} files processed.'.format(i, num_files))\n",
    "\n",
    "\n",
    "def main():\n",
    "    conn = psycopg2.connect(\"host=127.0.0.1 dbname=sparkifydb user=student password=student\")\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    process_data(cur, conn, filepath='data/song_data', func=process_song_file)\n",
    "    process_data(cur, conn, filepath='data/log_data', func=process_log_file)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipython-sql\n",
      "  Downloading https://files.pythonhosted.org/packages/ab/df/427e7cf05ffc67e78672ad57dce2436c1e825129033effe6fcaf804d0c60/ipython_sql-0.3.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: sqlalchemy>=0.6.7 in /Users/yuchen/anaconda3/lib/python3.6/site-packages (from ipython-sql) (1.2.7)\n",
      "Collecting sqlparse (from ipython-sql)\n",
      "  Downloading https://files.pythonhosted.org/packages/ef/53/900f7d2a54557c6a37886585a91336520e5539e3ae2423ff1102daf4f3a7/sqlparse-0.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: ipython-genutils>=0.1.0 in /Users/yuchen/anaconda3/lib/python3.6/site-packages (from ipython-sql) (0.2.0)\n",
      "Collecting prettytable (from ipython-sql)\n",
      "  Downloading https://files.pythonhosted.org/packages/ef/30/4b0746848746ed5941f052479e7c23d2b56d174b82f4fd34a25e389831f5/prettytable-0.7.2.tar.bz2\n",
      "Requirement already satisfied: six in /Users/yuchen/anaconda3/lib/python3.6/site-packages (from ipython-sql) (1.11.0)\n",
      "Requirement already satisfied: ipython>=1.0 in /Users/yuchen/anaconda3/lib/python3.6/site-packages (from ipython-sql) (6.4.0)\n",
      "Requirement already satisfied: backcall in /Users/yuchen/anaconda3/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (0.1.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /Users/yuchen/anaconda3/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (4.3.2)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /Users/yuchen/anaconda3/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (4.5.0)\n",
      "Requirement already satisfied: pygments in /Users/yuchen/anaconda3/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (2.2.0)\n",
      "Requirement already satisfied: appnope; sys_platform == \"darwin\" in /Users/yuchen/anaconda3/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (0.1.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/yuchen/anaconda3/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (39.1.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.15 in /Users/yuchen/anaconda3/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (1.0.15)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /Users/yuchen/anaconda3/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (0.8.1)\n",
      "Requirement already satisfied: decorator in /Users/yuchen/anaconda3/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (4.3.0)\n",
      "Requirement already satisfied: pickleshare in /Users/yuchen/anaconda3/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (0.7.4)\n",
      "Requirement already satisfied: jedi>=0.10 in /Users/yuchen/anaconda3/lib/python3.6/site-packages (from ipython>=1.0->ipython-sql) (0.12.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/yuchen/anaconda3/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=1.0->ipython-sql) (0.5.2)\n",
      "Requirement already satisfied: wcwidth in /Users/yuchen/anaconda3/lib/python3.6/site-packages (from prompt-toolkit<2.0.0,>=1.0.15->ipython>=1.0->ipython-sql) (0.1.7)\n",
      "Requirement already satisfied: parso>=0.2.0 in /Users/yuchen/anaconda3/lib/python3.6/site-packages (from jedi>=0.10->ipython>=1.0->ipython-sql) (0.2.0)\n",
      "Building wheels for collected packages: prettytable\n",
      "  Running setup.py bdist_wheel for prettytable ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/yuchen/Library/Caches/pip/wheels/80/34/1c/3967380d9676d162cb59513bd9dc862d0584e045a162095606\n",
      "Successfully built prettytable\n",
      "Installing collected packages: sqlparse, prettytable, ipython-sql\n",
      "Successfully installed ipython-sql-0.3.9 prettytable-0.7.2 sqlparse-0.3.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Connected: student@sparkifydb'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install ipython-sql\n",
    "%load_ext sql\n",
    "%sql postgresql://student:student@127.0.0.1/sparkifydb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://student:***@127.0.0.1/sparkifydb\n",
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>user_id</th>\n",
       "        <th>first_name</th>\n",
       "        <th>last_name</th>\n",
       "        <th>gender</th>\n",
       "        <th>level</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>69</td>\n",
       "        <td>Anabelle</td>\n",
       "        <td>Simpson</td>\n",
       "        <td>F</td>\n",
       "        <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>69</td>\n",
       "        <td>Anabelle</td>\n",
       "        <td>Simpson</td>\n",
       "        <td>F</td>\n",
       "        <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>69</td>\n",
       "        <td>Anabelle</td>\n",
       "        <td>Simpson</td>\n",
       "        <td>F</td>\n",
       "        <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>32</td>\n",
       "        <td>Lily</td>\n",
       "        <td>Burns</td>\n",
       "        <td>F</td>\n",
       "        <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>75</td>\n",
       "        <td>Joseph</td>\n",
       "        <td>Gutierrez</td>\n",
       "        <td>M</td>\n",
       "        <td>free</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(69, 'Anabelle', 'Simpson', 'F', 'free'),\n",
       " (69, 'Anabelle', 'Simpson', 'F', 'free'),\n",
       " (69, 'Anabelle', 'Simpson', 'F', 'free'),\n",
       " (32, 'Lily', 'Burns', 'F', 'free'),\n",
       " (75, 'Joseph', 'Gutierrez', 'M', 'free')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql SELECT * FROM users LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
